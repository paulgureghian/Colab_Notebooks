{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Medetec_Classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulgureghian/Google_Colab_PyTorch_Notebooks/blob/master/Medetec_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "fqQih7hWMmaK",
        "colab_type": "code",
        "outputId": "8215058f-2ad3-4492-e7f4-57874da77dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lwomz8yNOD5M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from collections import OrderedDict\n",
        "from torch.optim import lr_scheduler \n",
        "from torchvision import  models, datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WpJdybPMOgfo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/My Drive/Medetec/medetec_combined_split'\n",
        "train_dir = data_dir + '/train'\n",
        "valid_dir = data_dir + '/valid'\n",
        "test_dir = data_dir + '/test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RPI0h2et6UWk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_transforms= transforms.Compose([transforms.Resize(256),\n",
        "                                         transforms.RandomRotation(45),\n",
        "                                         transforms.RandomHorizontalFlip(),\n",
        "                                         transforms.RandomCrop(224),\n",
        "                                         transforms.RandomResizedCrop(224),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.485,0.456,0.406),\n",
        "                                                              (0.229,0.224,0.255))])\n",
        "\n",
        "validation_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                            transforms.CenterCrop(224),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize((0.485,0.456,0.406),\n",
        "                                                                 (0.229,0.224,0.255))])\n",
        "\n",
        "testing_transforms = transforms.Compose([transforms.Resize(256),\n",
        "                                         transforms.CenterCrop(224),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize((0.485,0.456,0.406),\n",
        "                                                              (0.229,0.224,0.255))])\n",
        "\n",
        "training_dataset = datasets.ImageFolder(train_dir, transform=training_transforms)\n",
        "validation_dataset = datasets.ImageFolder(valid_dir, transform=validation_transforms)\n",
        "testing_dataset = datasets.ImageFolder(test_dir, transform=testing_transforms)\n",
        "\n",
        "training_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=32, shuffle=True)\n",
        "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=32)\n",
        "testing_dataloader = torch.utils.data.DataLoader(testing_dataset, batch_size=32) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "msdlit-I_Qm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d70bc949-eb21-4618-b440-47a3a6d8265c"
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = models.vgg19(pretrained=True)\n",
        "\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad_(False) \n",
        "    \n",
        "model.classifier = nn.Sequential(OrderedDict([\n",
        "                                ('fc1', nn.Linear(25088, 4096)),\n",
        "                                ('relu1', nn.ReLU()),                                                             \n",
        "                                ('fc2', nn.Linear(4096, 15)), \n",
        "                                ('output', nn.LogSoftmax(dim=1))\n",
        "                                ])) \n",
        "\n",
        "model.to(device) \n",
        "epochs = 50\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.0005)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.torch/models/vgg19-dcbb9e9d.pth\n",
            "100%|██████████| 574673361/574673361 [00:07<00:00, 80082895.75it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_e2ZWlc7TKTC",
        "colab_type": "code",
        "outputId": "50f3c788-5394-4fb4-a7ad-b6c27df4e098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    scheduler.step()\n",
        "    train_loss = 0\n",
        "    \n",
        "    model.train()\n",
        "    for inputs, labels in training_dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        logps = model.forward(inputs)\n",
        "        \n",
        "        loss = criterion(logps, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss += loss.item()\n",
        "        \n",
        "    model.eval()\n",
        "    accuracy = 0\n",
        "    valid_loss = 0\n",
        "    \n",
        "    for inputs, labels in validation_dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        output = model.forward(inputs)\n",
        "        \n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        valid_loss += loss.item()\n",
        "        \n",
        "        ps = torch.exp(output)\n",
        "        top_ps, top_class = ps.topk(1, dim=1) \n",
        "        equals = top_class == labels.view(*top_class.shape)\n",
        "        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "        \n",
        "    print('Epoch {}/{}.. '.format(epoch+1, epochs),\n",
        "          'Training loss: {:.3f}.. '.format(train_loss / len(training_dataloader)),\n",
        "          'Validation loss: {:.3f}.. '.format(valid_loss / len(validation_dataloader)),\n",
        "          'Validation accuracy: {:.3f}.. '.format(accuracy / len(validation_dataloader)))\n",
        "          \n",
        "    model.train()      "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50..  Training loss: 3.236..  Validation loss: 1.875..  Validation accuracy: 0.361.. \n",
            "Epoch 2/50..  Training loss: 1.929..  Validation loss: 1.824..  Validation accuracy: 0.339.. \n",
            "Epoch 3/50..  Training loss: 1.729..  Validation loss: 1.777..  Validation accuracy: 0.405.. \n",
            "Epoch 4/50..  Training loss: 1.572..  Validation loss: 1.682..  Validation accuracy: 0.459.. \n",
            "Epoch 5/50..  Training loss: 1.452..  Validation loss: 1.764..  Validation accuracy: 0.438.. \n",
            "Epoch 6/50..  Training loss: 1.420..  Validation loss: 1.654..  Validation accuracy: 0.493.. \n",
            "Epoch 7/50..  Training loss: 1.400..  Validation loss: 1.761..  Validation accuracy: 0.483.. \n",
            "Epoch 8/50..  Training loss: 1.282..  Validation loss: 1.697..  Validation accuracy: 0.474.. \n",
            "Epoch 9/50..  Training loss: 1.302..  Validation loss: 1.756..  Validation accuracy: 0.500.. \n",
            "Epoch 10/50..  Training loss: 1.244..  Validation loss: 1.508..  Validation accuracy: 0.500.. \n",
            "Epoch 11/50..  Training loss: 1.192..  Validation loss: 1.758..  Validation accuracy: 0.451.. \n",
            "Epoch 12/50..  Training loss: 1.141..  Validation loss: 1.832..  Validation accuracy: 0.516.. \n",
            "Epoch 13/50..  Training loss: 1.221..  Validation loss: 1.624..  Validation accuracy: 0.511.. \n",
            "Epoch 14/50..  Training loss: 1.045..  Validation loss: 1.874..  Validation accuracy: 0.543.. \n",
            "Epoch 15/50..  Training loss: 1.107..  Validation loss: 1.708..  Validation accuracy: 0.522.. \n",
            "Epoch 16/50..  Training loss: 1.074..  Validation loss: 1.852..  Validation accuracy: 0.467.. \n",
            "Epoch 17/50..  Training loss: 1.088..  Validation loss: 1.831..  Validation accuracy: 0.472.. \n",
            "Epoch 18/50..  Training loss: 0.976..  Validation loss: 1.926..  Validation accuracy: 0.506.. \n",
            "Epoch 19/50..  Training loss: 1.033..  Validation loss: 1.749..  Validation accuracy: 0.528.. \n",
            "Epoch 20/50..  Training loss: 0.924..  Validation loss: 2.159..  Validation accuracy: 0.455.. \n",
            "Epoch 21/50..  Training loss: 0.896..  Validation loss: 1.897..  Validation accuracy: 0.486.. \n",
            "Epoch 22/50..  Training loss: 0.894..  Validation loss: 1.911..  Validation accuracy: 0.547.. \n",
            "Epoch 23/50..  Training loss: 0.917..  Validation loss: 1.861..  Validation accuracy: 0.528.. \n",
            "Epoch 24/50..  Training loss: 0.926..  Validation loss: 1.976..  Validation accuracy: 0.487.. \n",
            "Epoch 25/50..  Training loss: 0.910..  Validation loss: 2.060..  Validation accuracy: 0.455.. \n",
            "Epoch 26/50..  Training loss: 0.832..  Validation loss: 2.079..  Validation accuracy: 0.505.. \n",
            "Epoch 27/50..  Training loss: 0.923..  Validation loss: 2.082..  Validation accuracy: 0.460.. \n",
            "Epoch 28/50..  Training loss: 0.845..  Validation loss: 1.976..  Validation accuracy: 0.526.. \n",
            "Epoch 29/50..  Training loss: 0.807..  Validation loss: 2.128..  Validation accuracy: 0.553.. \n",
            "Epoch 30/50..  Training loss: 0.797..  Validation loss: 2.160..  Validation accuracy: 0.510.. \n",
            "Epoch 31/50..  Training loss: 0.758..  Validation loss: 2.109..  Validation accuracy: 0.493.. \n",
            "Epoch 32/50..  Training loss: 0.736..  Validation loss: 2.141..  Validation accuracy: 0.488.. \n",
            "Epoch 33/50..  Training loss: 0.667..  Validation loss: 2.101..  Validation accuracy: 0.488.. \n",
            "Epoch 34/50..  Training loss: 0.726..  Validation loss: 2.104..  Validation accuracy: 0.483.. \n",
            "Epoch 35/50..  Training loss: 0.711..  Validation loss: 2.099..  Validation accuracy: 0.488.. \n",
            "Epoch 36/50..  Training loss: 0.730..  Validation loss: 2.086..  Validation accuracy: 0.488.. \n",
            "Epoch 37/50..  Training loss: 0.629..  Validation loss: 2.115..  Validation accuracy: 0.498.. \n",
            "Epoch 38/50..  Training loss: 0.602..  Validation loss: 2.109..  Validation accuracy: 0.488.. \n",
            "Epoch 39/50..  Training loss: 0.612..  Validation loss: 2.083..  Validation accuracy: 0.504.. \n",
            "Epoch 40/50..  Training loss: 0.629..  Validation loss: 2.128..  Validation accuracy: 0.493.. \n",
            "Epoch 41/50..  Training loss: 0.675..  Validation loss: 2.132..  Validation accuracy: 0.498.. \n",
            "Epoch 42/50..  Training loss: 0.631..  Validation loss: 2.143..  Validation accuracy: 0.498.. \n",
            "Epoch 43/50..  Training loss: 0.644..  Validation loss: 2.140..  Validation accuracy: 0.519.. \n",
            "Epoch 44/50..  Training loss: 0.622..  Validation loss: 2.134..  Validation accuracy: 0.514.. \n",
            "Epoch 45/50..  Training loss: 0.626..  Validation loss: 2.088..  Validation accuracy: 0.556.. \n",
            "Epoch 46/50..  Training loss: 0.590..  Validation loss: 2.127..  Validation accuracy: 0.508.. \n",
            "Epoch 47/50..  Training loss: 0.677..  Validation loss: 2.154..  Validation accuracy: 0.519.. \n",
            "Epoch 48/50..  Training loss: 0.624..  Validation loss: 2.168..  Validation accuracy: 0.535.. \n",
            "Epoch 49/50..  Training loss: 0.642..  Validation loss: 2.141..  Validation accuracy: 0.530.. \n",
            "Epoch 50/50..  Training loss: 0.613..  Validation loss: 2.100..  Validation accuracy: 0.535.. \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}